{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1mzy2J8_nc1"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EXwoz-KHtWO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Gs6Lyc_pd0"
      },
      "source": [
        "## Load and prepare the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9F7YsCNIKSA"
      },
      "outputs": [],
      "source": [
        "# preprocessing function\n",
        "def map_image(image, label):\n",
        "  image = tf.cast(image, dtype=tf.float32)\n",
        "  image = image / 255.0\n",
        "\n",
        "  return image, image\n",
        "\n",
        "# parameters\n",
        "BATCH_SIZE = 64\n",
        "SHUFFLE_BUFFER_SIZE = 1024\n",
        "\n",
        "# use tfds.load() to fetch the 'train' split of CIFAR-10\n",
        "train_dataset = tfds.load('cifar10',as_supervised = True,split = 'train')\n",
        "# preprocess the dataset with the `map_image()` function above\n",
        "train_dataset = train_dataset.map(map_image)\n",
        "# shuffle and batch the dataset\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "# use tfds.load() to fetch the 'test' split of CIFAR-10\n",
        "test_dataset = tfds.load('cifar10',as_supervised = True,split = 'test')\n",
        "# preprocess the dataset with the `map_image()` function above\n",
        "test_dataset = test_dataset.map(map_image)\n",
        "# batch the dataset\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPyOgGJs_t98"
      },
      "source": [
        "## Build the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr-Bok3lRgA3"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.layers.Input(shape = (32,32,3))\n",
        "conv_1 = tf.keras.layers.Conv2D(64,kernel_size = (3,3),activation = 'relu',padding = 'same')(inputs)\n",
        "max_pool_1 = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv_1)\n",
        "conv_2 = tf.keras.layers.Conv2D(128,kernel_size = (3,3),activation = 'relu',padding = 'same')(max_pool_1)\n",
        "max_pool_2 = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv_2)\n",
        "\n",
        "bottleneck = tf.keras.layers.Conv2D(256,kernel_size =(3,3),activation = 'relu',padding = 'same')(max_pool_2)\n",
        "\n",
        "conv_3 = tf.keras.layers.Conv2D(128,kernel_size = (3,3),activation = 'relu',padding = 'same')(bottleneck)\n",
        "up_sample_1 = tf.keras.layers.UpSampling2D(size = (2,2))(conv_3)\n",
        "conv_4 = tf.keras.layers.Conv2D(64,kernel_size = (3,3),activation = 'relu',padding = 'same')(up_sample_1)\n",
        "up_sample_2 = tf.keras.layers.UpSampling2D(size = (2,2))(conv_4)\n",
        "\n",
        "decoder_output = tf.keras.layers.Conv2D(3,kernel_size = (3,3),activation = 'sigmoid',padding = 'same')(up_sample_2)\n",
        "\n",
        "model = tf.keras.Model(inputs = inputs,outputs = decoder_output)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRWTAijKEVUC"
      },
      "source": [
        "## Configure training parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHIeD9eDETSk"
      },
      "outputs": [],
      "source": [
        "# Please do not change the model.compile() parameters\n",
        "model.compile(optimizer='adam', metrics=['accuracy'], loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLQPhm1W_8dC"
      },
      "source": [
        "## Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMBimOnsRvg0"
      },
      "outputs": [],
      "source": [
        "train_steps = len(train_dataset) // BATCH_SIZE\n",
        "val_steps = len(test_dataset) // BATCH_SIZE\n",
        "\n",
        "model.fit(train_dataset, steps_per_epoch=train_steps, validation_data=test_dataset, validation_steps=val_steps, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT2l1c-SAaF4"
      },
      "source": [
        "## Model evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFncgqahSQhA"
      },
      "outputs": [],
      "source": [
        "result = model.evaluate(test_dataset, steps=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvw0HLY2kV3w"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULCfGHEKkaO0"
      },
      "outputs": [],
      "source": [
        "# Save the model you just trained\n",
        "model.save(\"temp_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljeWKuSKYEHE"
      },
      "outputs": [],
      "source": [
        "# Load the model you saved earlier\n",
        "model = tf.keras.models.load_model(\"temp_model.h5\", compile=False)\n",
        "\n",
        "# For this assignment only. The model has to be compiled with these settings.\n",
        "model.compile(optimizer='adam', metrics=['accuracy'], loss='mean_squared_error')\n",
        "\n",
        "# Save the model with the compatible TF version\n",
        "model.save(\"mymodel.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCd50-pubX_o"
      },
      "outputs": [],
      "source": [
        "# You can also use this cell as a shortcut for downloading your model\n",
        "from google.colab import files\n",
        "files.download(\"mymodel.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}