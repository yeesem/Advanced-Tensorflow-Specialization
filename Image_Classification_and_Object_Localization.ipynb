{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbC5d2v0PJpK+V+jOIqvJH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeesem/Advanced-Tensorflow-Specialization/blob/main/Image_Classification_and_Object_Localization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "WgiJvBsSJxa5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vknIW68MJJLs"
      },
      "outputs": [],
      "source": [
        "import os,re,time,json\n",
        "import PIL.Image,PIL.ImageFont,PIL.ImageDraw\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization Utilities"
      ],
      "metadata": {
        "id": "8H3DO9R3J1vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im_width = 75\n",
        "im_height = 75\n",
        "use_normalized_coordinates = True\n",
        "\n",
        "def draw_bounding_boxes_on_image_array(\n",
        "    image,\n",
        "    boxes,\n",
        "    color = [],\n",
        "    thickness = 1,\n",
        "    display_str_list = ()\n",
        "):\n",
        "  # The input image, which is a NumPy array, is converted into a PIL\n",
        "  # (Python Imaging Library) image object using PIL.Image.fromarray.\n",
        "  image_pil = PIL.Image.fromaarray(image)\n",
        "  # A new RGBA image is created with the same size as the original image.\n",
        "  # The \"RGBA\" mode means that the new image will have Red, Green, Blue, and\n",
        "  # Alpha (transparency) channels.\n",
        "  rgbimg = PIL.Image.new(\"RGBA\",image_pil.size)\n",
        "  # Paste the Original Image onto the RGBA Image:\n",
        "  rgbimg.paste(image_pil)\n",
        "  draw_bounding_boxes_on_image(rgbimg,boxes,color,thickness,\n",
        "                               display_str_list)\n",
        "  return np.array(rgbimg)\n",
        "\n",
        "def draw_bounding_boxes_on_image(\n",
        "    image,\n",
        "    boxes,\n",
        "    color = [],\n",
        "    thickness = 1,\n",
        "    display_str_list = ()\n",
        "):\n",
        "  boxes_shape = boxes.shape\n",
        "  if not boxes_shape:\n",
        "    return\n",
        "  if len(boxes_shape)!=2 or boxes_shape[1] != 4:\n",
        "    raise ValueError(\"Input must be of size [N,4]\")\n",
        "  for i in range(boxes_shape[0]):\n",
        "    draw_bounding_box_on_image(image,boxes[i,1],boxes[i,0],boxes[i,3],\n",
        "                               boxes[i,2],color[i],thickness,display_str_list[i])\n",
        "\n",
        "def draw_bounding_box_on_image(\n",
        "    image,\n",
        "    ymin,\n",
        "    xmin,\n",
        "    ymax,\n",
        "    xmax,\n",
        "    color = 'red',\n",
        "    thickness = 1,\n",
        "    display_str = None,\n",
        "    use_normalized_coordinates = True\n",
        "):\n",
        "  draw = PIL.ImageDraw.Draw(image)\n",
        "  im_width,im_height = image.size\n",
        "  if use_normalized_coordinates:\n",
        "    (left,right,top,bottom) = (xmin * im_width,xmax * im_width,\n",
        "                               ymin* im_height,ymax * im_height)\n",
        "  else:\n",
        "    (left,right,top,bottom) = (xmin,xmax,ymin,ymax)\n",
        "\n",
        "  draw.line([(left,top),(left,bottom),(right,bottom),\n",
        "             (right,top),(left,top)],width = thickness,fill = color)\n"
      ],
      "metadata": {
        "id": "5dzf3IX0Jpm0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rc('image',cmap='gray')\n",
        "plt.rc('grid',linewidth = 0)\n",
        "plt.rc('xtick',top = False,bottom = False,labelsize = 'large')\n",
        "plt.rc('ytick',left = False,right = False,labelsize = 'large')\n",
        "plt.rc('axes',facecolor = 'F8F8F8',titlesize = 'large',edgecolor = 'white')\n",
        "plt.rc('text',color = 'a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
        "\n",
        "def dataset_to_numpy_util(training_dataset,validation_dataset,N):\n",
        "\n",
        "  # get one batch from each: 10000 validation digits, N training digits\n",
        "  batch_train_ds = training_dataset.unbatch().batch(N)\n",
        "\n",
        "  # Eager execution : Loop through datasets normally\n",
        "  if tf.executing_eagerly():\n",
        "    for validation_digits, (validation_labels,validation_bboxes) in validation_dataset:\n",
        "      validation_digits = validation_digits.numpy()\n",
        "      validation_labels = validation_labels.numpy()\n",
        "      validation_bboxes = validation_bboxes.numpy()\n",
        "      break\n",
        "    for training_digits, (training_labels,training_bboxes) in batch_train_ds:\n",
        "      training_digits = training_digits.numpy()\n",
        "      training_labels = training_labels.numpy()\n",
        "      training_bboxes = training_bboxes.numpy()\n",
        "      break\n",
        "\n",
        "    # these were one-hot encoded in the dataset\n",
        "    validation_labels = np.argmax(validation_labels,axis = 1)\n",
        "    training_labels = np.argmax(training_labels,axis = 1)\n",
        "\n",
        "    return (training_digits, training_labels, training_bboxes,\n",
        "          validation_digits, validation_labels, validation_bboxes)\n",
        "\n"
      ],
      "metadata": {
        "id": "2yZmLTd8Qq_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}