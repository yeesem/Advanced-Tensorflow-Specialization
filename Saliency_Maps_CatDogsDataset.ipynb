{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeesem/Advanced-Tensorflow-Specialization/blob/main/Saliency_Maps_CatDogsDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDHISSfBq40T"
      },
      "source": [
        "### Download test files and weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Laatr1c6lr1w"
      },
      "outputs": [],
      "source": [
        "# Download the same test files from the Cats vs Dogs ungraded lab\n",
        "!wget -O cat1.jpg https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/cat1.jpeg\n",
        "!wget -O cat2.jpg https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/cat2.jpeg\n",
        "!wget -O catanddog.jpg https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/catanddog.jpeg\n",
        "!wget -O dog1.jpg https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/dog1.jpeg\n",
        "!wget -O dog2.jpg https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/MLColabImages/dog2.jpeg\n",
        "\n",
        "# Download prepared weights\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1kipXTxesGJKGY1B8uSPRvxROgOH90fih' -O 0_epochs.h5\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1oiV6tjy5k7h9OHGTQaf0Ohn3FmF-uOs1' -O 15_epochs.h5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g24L3lKwqb3E"
      },
      "source": [
        "### Import the required packages\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X86LKLvpBO2S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th4dA3I8-9Ue"
      },
      "source": [
        "### Download and prepare the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1hujOK9rDyU"
      },
      "source": [
        "#### Load Cats vs Dogs Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w5HNdoHBQv_"
      },
      "outputs": [],
      "source": [
        "# Load the data and create the train set (optional: val and test sets)\n",
        "train_data = tfds.load('cats_vs_dogs',split = 'train[:80%]',as_supervised = True)\n",
        "validation_data = tfds.load('cats_vs_dogs',split = 'train[:80%]',as_supervised = True )\n",
        "test_data = tfds.load('cats_vs_dogs',split = 'train[80%:90%]',as_supervised = True)\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXp0mV5Rbo76"
      },
      "source": [
        "#### Create preprocessing function\n",
        "\n",
        "Define a function that takes in an image and label. This will:\n",
        "  * cast the image to float32\n",
        "  * normalize the pixel values to [0, 1]\n",
        "  * resize the image to 300 x 300\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRkrL2aK2_UZ"
      },
      "outputs": [],
      "source": [
        "def augment_images(image, label):\n",
        "  # YOUR CODE HERE\n",
        "  image = tf.cast(image,tf.float32)\n",
        "\n",
        "  # Normalize the pixel values\n",
        "  image = image / 255.0\n",
        "\n",
        "  # Resize to 300 x 300\n",
        "  image = tf.image.resize(image,(300,300))\n",
        "\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzvF61GV32k_"
      },
      "source": [
        "#### Preprocess the training set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpNEfDKM353a"
      },
      "outputs": [],
      "source": [
        "augmented_training_data = train_data.map(augment_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4nFaMIMbrvA"
      },
      "source": [
        "#### Create batches of the training set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POhDDPBY3vnL"
      },
      "outputs": [],
      "source": [
        "train_batches = augmented_training_data.batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za5HxgT1_Cw6"
      },
      "source": [
        "### Build the Cats vs Dogs classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoyCA80GBSlG"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(Conv2D(16,input_shape = (300,300,3),kernel_size = (3,3),activation = 'relu',padding = 'same'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(32,kernel_size = (3,3),activation = 'relu',padding = 'same'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size = (3,3),activation = 'relu',padding = 'same'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size = (3,3),activation = 'relu',padding = 'same'))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(2,activation = 'softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6nou82P_b5d"
      },
      "source": [
        "### Create a function to generate the saliency map\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKbvh3bl9vnG"
      },
      "outputs": [],
      "source": [
        "def do_salience(image, model, label, prefix):\n",
        "\n",
        "  # Read the image and convert channel order from BGR to RGB\n",
        "  img = cv2.imread(image)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # Resize the image to 300 x 300 and normalize pixel values to the range [0, 1]\n",
        "  img = cv2.resize(img, (300, 300)) / 255.0\n",
        "\n",
        "  # Add an additional dimension (for the batch), and save this in a new variable\n",
        "  exp_image = np.expand_dims(img, axis=0)\n",
        "\n",
        "  # Declare the number of classes\n",
        "  num_classes = 2\n",
        "\n",
        "  # Define the expected output array by one-hot encoding the label\n",
        "  # The length of the array is equal to the number of classes\n",
        "  expected_output = tf.one_hot([label] * exp_image.shape[0], num_classes)\n",
        "\n",
        "  # Witin the GradientTape block:\n",
        "  # Cast the image as a tf.float32\n",
        "  # Use the tape to watch the float32 image\n",
        "  # Get the model's prediction by passing in the float32 image\n",
        "  # Compute an appropriate loss\n",
        "  # between the expected output and model predictions.\n",
        "  # you may want to print the predictions to see if the probabilities adds up to 1\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "      inputs = tf.cast(exp_image, dtype=tf.float32)\n",
        "      tape.watch(inputs)\n",
        "      prediction = model(inputs)\n",
        "      loss = tf.keras.losses.categorical_crossentropy(expected_output, prediction)\n",
        "\n",
        "      print(prediction)\n",
        "\n",
        "  # get the gradients of the loss with respect to the model's input image\n",
        "\n",
        "  gradients = tape.gradient(loss, inputs)\n",
        "\n",
        "  # generate the grayscale tensor\n",
        "  grayscale_tensor = tf.reduce_sum(tf.abs(gradients), axis = -1)\n",
        "\n",
        "  # normalize the pixel values to be in the range [0, 255].\n",
        "  # the max value in the grayscale tensor will be pushed to 255.\n",
        "  # the min value will be pushed to 0.\n",
        "  # Use the formula: 255 * (x - min) / (max - min)\n",
        "  # Use tf.reduce_max, tf.reduce_min\n",
        "  # Cast the tensor as a tf.uint8\n",
        "\n",
        "  normalized_tensor = tf.cast(\n",
        "    255 * (grayscale_tensor - tf.reduce_min(grayscale_tensor)) / (tf.reduce_max(grayscale_tensor) - tf.reduce_min(grayscale_tensor)),\n",
        "    tf.uint8)\n",
        "\n",
        "\n",
        "  # Remove dimensions that are size 1\n",
        "  normalized_tensor = tf.squeeze(normalized_tensor)\n",
        "\n",
        "\n",
        "  # plot the normalized tensor\n",
        "  # Set the figure size to 8 by 8\n",
        "  # do not display the axis\n",
        "  # use the 'gray' colormap\n",
        "  # This code is provided for you.\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(normalized_tensor, cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "  # optional: superimpose the saliency map with the original image, then display it.\n",
        "  # we encourage you to do this to visualize your results better\n",
        "  gradient_color = cv2.applyColorMap(normalized_tensor.numpy(), cv2.COLORMAP_HOT)\n",
        "  gradient_color = gradient_color / 255.0\n",
        "  super_imposed = cv2.addWeighted(img, 0.7, gradient_color, 0.3, 0.0)\n",
        "\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(super_imposed)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  # save the normalized tensor image to a file. this is already provided for you.\n",
        "  salient_image_name = prefix + image\n",
        "  normalized_tensor = tf.expand_dims(normalized_tensor, -1)\n",
        "  normalized_tensor = tf.io.encode_jpeg(normalized_tensor, quality=100, format='grayscale')\n",
        "  writer = tf.io.write_file(salient_image_name, normalized_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li1idRy-parp"
      },
      "source": [
        "### Generate saliency maps with untrained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k39fF4n8fgG0"
      },
      "outputs": [],
      "source": [
        "# load initial weights\n",
        "model.load_weights('0_epochs.h5')\n",
        "\n",
        "# generate the saliency maps for the 5 test images\n",
        "# YOUR CODE HERE\n",
        "img_list = ['cat1.jpg', 'cat2.jpg', 'catanddog.jpg', 'dog1.jpg', 'dog2.jpg']\n",
        "img_label = [0,0,0,1,1]\n",
        "for i,l in zip(img_list,img_label):\n",
        "  do_salience(i,model,l,'epoch0_salient')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kcdyut5E2Tk"
      },
      "source": [
        "With untrained weights, you will see something like this in the output.\n",
        "- You will see strong pixels outside the cat that the model uses that when classifying the image.\n",
        "- After training that these will slowly start to localize to features inside the pet.\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1h5wP52lwbBUMVLlsgyb-tQl_I9eu42X7' alt='saliency'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZhZgd0x_JvN"
      },
      "source": [
        "### Configure the model for training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkyWZ5KdBo-z"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.RMSprop(),\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otIoJJw7_ZFN"
      },
      "source": [
        "### Train your model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YSNp7k7BqfL"
      },
      "outputs": [],
      "source": [
        "# load pre-trained weights\n",
        "model.load_weights('15_epochs.h5')\n",
        "\n",
        "# train the model for just 3 epochs\n",
        "history = model.fit(train_batches,epochs = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tTqtLN3tQJx"
      },
      "source": [
        "### Generate saliency maps at 18 epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXFtabyVhIKN"
      },
      "outputs": [],
      "source": [
        "for i,l in zip(img_list,img_label):\n",
        "  do_salience(i,model,l,'salient')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}