{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPP9Y+hOF/ZFsgva0Px9gjw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "915e44b65e624af493df97de553b3c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a06a265396a344a2937a8c114c9a73ef",
              "IPY_MODEL_24e41574edcc4cb9b6977f125f447761",
              "IPY_MODEL_9df700e75a464614b4654ee238f6057b"
            ],
            "layout": "IPY_MODEL_f2e3ec1b59524b0ab864f0ffa940d29e"
          }
        },
        "a06a265396a344a2937a8c114c9a73ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f95c3b9b977b4306bc12f7444e690180",
            "placeholder": "​",
            "style": "IPY_MODEL_8a190e6ce5114358a1c695f62e7371c8",
            "value": "Dl Completed...: 100%"
          }
        },
        "24e41574edcc4cb9b6977f125f447761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b17f17d9e0048128edece2e310ec171",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a82a4e065c5a423dbd8983f6f23a1ac4",
            "value": 5
          }
        },
        "9df700e75a464614b4654ee238f6057b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fae72fe6bc28453d9798635f8f90c1a4",
            "placeholder": "​",
            "style": "IPY_MODEL_8e4490b941454fb982e6a96427fdd9dd",
            "value": " 5/5 [00:00&lt;00:00, 12.63 file/s]"
          }
        },
        "f2e3ec1b59524b0ab864f0ffa940d29e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f95c3b9b977b4306bc12f7444e690180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a190e6ce5114358a1c695f62e7371c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b17f17d9e0048128edece2e310ec171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a82a4e065c5a423dbd8983f6f23a1ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fae72fe6bc28453d9798635f8f90c1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e4490b941454fb982e6a96427fdd9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "W1vWm2-43Dax"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F5A5FXlX27if"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "pKNwJEeP3N3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define global constants\n",
        "BATCH_SIZE = 32\n",
        "LATENT_DIM = 2"
      ],
      "metadata": {
        "id": "IUf2JdFg3M-m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Dataset"
      ],
      "metadata": {
        "id": "Ujs7wDhf3bo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_image(image,label):\n",
        "  image = tf.cast(image,tf.float32)\n",
        "  image = image / 255.0\n",
        "  image = tf.reshape(image,shape = (28,28,1,))\n",
        "  return image\n",
        "\n",
        "def get_dataset(map_fn,is_validation = False):\n",
        "  if is_validation:\n",
        "    split_name = 'test'\n",
        "  else:\n",
        "    split_name = 'train'\n",
        "\n",
        "  dataset = tfds.load('mnist',as_supervised = True,split = split_name)\n",
        "  dataset = dataset.map(map_fn)\n",
        "\n",
        "  if is_validation:\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "  else:\n",
        "    dataset = dataset.shuffle(1024).batch(BATCH_SIZE)\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "kVGko-WT3bGT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_dataset(map_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "915e44b65e624af493df97de553b3c7f",
            "a06a265396a344a2937a8c114c9a73ef",
            "24e41574edcc4cb9b6977f125f447761",
            "9df700e75a464614b4654ee238f6057b",
            "f2e3ec1b59524b0ab864f0ffa940d29e",
            "f95c3b9b977b4306bc12f7444e690180",
            "8a190e6ce5114358a1c695f62e7371c8",
            "8b17f17d9e0048128edece2e310ec171",
            "a82a4e065c5a423dbd8983f6f23a1ac4",
            "fae72fe6bc28453d9798635f8f90c1a4",
            "8e4490b941454fb982e6a96427fdd9dd"
          ]
        },
        "id": "Wj0B2MXBJ9Ll",
        "outputId": "4df1d98d-f81b-4398-f618-328d6f620674"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "915e44b65e624af493df97de553b3c7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Model"
      ],
      "metadata": {
        "id": "1JMi-w68KCJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1YAZAeMGEJ1KgieYk1ju-S9DoshpMREeC\" width=\"60%\" height=\"60%\"/>"
      ],
      "metadata": {
        "id": "LcMrDTFzKEGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling Class"
      ],
      "metadata": {
        "id": "Ui8QfYbIKN8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(tf.keras.layers.Layer):\n",
        "  def call(self,inputs):\n",
        "    # Unpack the output of the encoder\n",
        "    mu,sigma = inputs\n",
        "\n",
        "    # Get the size and dimensions of the batch\n",
        "    batch = tf.shape(mu)[0]\n",
        "    dim = tf.shape(mu)[1]\n",
        "\n",
        "    # Generate a random tensor\n",
        "    epsilon = tf.keras.backend.random_normal(shape = (batch,dim))\n",
        "\n",
        "    # Combine the inputs and noise\n",
        "    return mu + sigma * epsilon"
      ],
      "metadata": {
        "id": "VEx3e96CKJFZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "uQyRnP83KxTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1eoxFK_UVSHd3a_5EHcCU8F8QDZlPiXfW\" width=\"60%\" height=\"60%\"/>"
      ],
      "metadata": {
        "id": "SC1XHtiQK6_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_layer(inputs,latent_dim):\n",
        "  # Add the Conv2D followed by BatchNormalization\n",
        "  x = tf.keras.layers.Conv2D(32,kernel_size = 3,strides = 2,padding = 'same',activation = 'relu',name = 'encode_conv1')(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2D(64,kernel_size = 3,strides = 2,padding = 'same',activation = 'relu',name = 'encode_conv2')(x)\n",
        "\n",
        "  # Assign to a different variable so can extract the shape later\n",
        "  batch_2 = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  # Flatten the features and feed into the Dense network\n",
        "  x = tf.keras.layers.Flatten(name = 'encode_flatten')(batch_2)\n",
        "\n",
        "  # we arbitrarily used 20 units here but feel free to change and see what results you get\n",
        "  x = tf.keras.layers.Dense(20,activation = 'relu',name = 'encode_dense')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  # Add output Dense network for mu and sigma, units equal to the declared latend_dim\n",
        "  mu = tf.keras.layers.Dense(latent_dim,name = 'latent_mu')(x)\n",
        "  sigma = tf.keras.layers.Dense(latent_dim,name = 'latent_sigma')(x)\n",
        "\n",
        "  return mu,sigma,batch_2.shape"
      ],
      "metadata": {
        "id": "eiTJ8EbuKyuZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_model(latent_dim,input_shape):\n",
        "  # Declare the inputs tensor with the given shape\n",
        "  inputs = tf.keras.layers.Input(shape = input_shape)\n",
        "\n",
        "  # Get the output of the encoder_layers() function\n",
        "  mu,sigma,conv_shape = encoder_layer(inputs,latent_dim = LATENT_DIM)\n",
        "\n",
        "  # Feed mu and sigma to the sampling layer\n",
        "  z = Sampling()((mu,sigma))\n",
        "\n",
        "  # Build the whole encoder model\n",
        "  model = tf.keras.Model(inputs,outputs = [mu,sigma,z])\n",
        "\n",
        "  return model,conv_shape"
      ],
      "metadata": {
        "id": "NUugsQKuMkxq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder"
      ],
      "metadata": {
        "id": "9XKJclsUNNah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_layer(inputs,conv_shape):\n",
        "  units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
        "  x = tf.keras.layers.Dense(units,activation = 'relu',name = 'decode_dense1')(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  # Reshape the output using the conv_shape dimensions\n",
        "  x = tf.keras.layers.Reshape((conv_shape[1],conv_shape[2],conv_shape[3]),name = 'decode_reshape')(x)\n",
        "\n",
        "  # Upsample the features back to the original dimensions\n",
        "  x = tf.keras.layers.Conv2DTranspose(64,kernel_size = 3,strides = 2,padding = 'same',activation = 'relu',name = 'decode_conv2d_2')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(32,kernel_size = 3,strides = 2,padding = 'same',activation = 'relu',name = 'decode_conv2d_3')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(1,kernel_size = 3,strides = 2,padding = 'same', activation = 'sigmoid',name = 'decode_final')(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "2zXa5X-iNO5_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_model(latend_dim,conv_shape):\n",
        "  # Set the inputs to the shape of the latend space\n",
        "  inputs = tf.keras.layers.Input(shape = (latend_dim,))\n",
        "\n",
        "  # Get the output of the decoder layers\n",
        "  outputs = decoder_layer(inputs,conv_shape)\n",
        "\n",
        "  # Declare the inputs and outputs of the model\n",
        "  model = tf.keras.Model(inputs,outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "_8_eHy6BOvjG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kullback-Leibler Divergence"
      ],
      "metadata": {
        "id": "mxKw3wfkPKLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kl_reconstruction_loss(mu,sigma):\n",
        "  kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)\n",
        "  kl_loss = tf.reduce_mean(kl_loss) * -0.5\n",
        "\n",
        "  return kl_loss"
      ],
      "metadata": {
        "id": "zMqRpsvuPMzk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE Model"
      ],
      "metadata": {
        "id": "SAVbFVnXPbtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_model(encoder,decoder,input_shape):\n",
        "  # Set the inputs\n",
        "  inputs = tf.keras.layers.Input(shape = input_shape)\n",
        "\n",
        "  # Get the mu,sigma and z from the encoder output\n",
        "  mu,sigma,z = encoder(inputs)\n",
        "\n",
        "  # Get the reconstructed from the decoder\n",
        "  reconstructed = decoder(z)\n",
        "\n",
        "  # Define the inputs and outputs of the VAE\n",
        "  model = tf.keras.Model(inputs,outputs = reconstructed)\n",
        "\n",
        "  # Add the KL loss\n",
        "  loss = kl_reconstruction_loss(mu,sigma)\n",
        "  model.add_loss(loss)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "f5eGC0LNPfll"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models(input_shape,latent_dim):\n",
        "  encoder,conv_shape = encoder_model(latent_dim = latent_dim,input_shape = input_shape)\n",
        "  decoder = decoder_model(latent_dim,conv_shape = conv_shape)\n",
        "  vae = vae_model(encoder,decoder,input_shape = input_shape)\n",
        "  return encoder,decoder,vae"
      ],
      "metadata": {
        "id": "uM6yV6nsP5wY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the encoder,decoder and 'master' model [VAE]\n",
        "encoder,decoder,vae = get_models(input_shape = (28,28,1,),latent_dim = LATENT_DIM)"
      ],
      "metadata": {
        "id": "4AOuBEvEQ3Y-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "JTXgjv6TR2km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizers\n",
        "ootimizer = tf.keras.optimizers.Adam()\n",
        "loss_metric = tf.keras.metrics.Mean()\n",
        "bce_loss = tf.keras.losses.BinaryCrossentropy()"
      ],
      "metadata": {
        "id": "bCHdw19sR4RS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model,epoch,step,test_input):\n",
        "  # Generate iamges from the test input\n",
        "  predictions = model.predict(test_input)\n",
        "\n",
        "  # Plot the results\n",
        "  fig = plt.figure(figsize = (4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(predictions[i,:,:,0],cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "  # tight_layout minimized the overlap between 2 subplots\n",
        "  fig.suptitle(\"epoch: {}, step: {}\".format(epoch,step))\n",
        "  plt.savefig('image_at_epoch_{:04d}_step{:04d}.png'.format(epoch,step))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "APufvKY5SF3v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}