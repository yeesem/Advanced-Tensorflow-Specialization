{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9KVlsuigA+QFmilDuAL9c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "W1vWm2-43Dax"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5A5FXlX27if"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "pKNwJEeP3N3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define global constants\n",
        "BATCH_SIZE = 32\n",
        "LATENT_DIM = 2"
      ],
      "metadata": {
        "id": "IUf2JdFg3M-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Dataset"
      ],
      "metadata": {
        "id": "Ujs7wDhf3bo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_image(image,label):\n",
        "  image = tf.cast(image,tf.float32)\n",
        "  image = image / 255.0\n",
        "  image = tf.reshape(image,shape = (28,28,1,))\n",
        "  return image\n",
        "\n",
        "def get_dataset(map_fn,is_validation = False):\n",
        "  if is_validation:\n",
        "    split_name = 'test'\n",
        "  else:\n",
        "    split_name = 'train'\n",
        "\n",
        "  dataset = tfds.load('mnist',as_supervised = True,split = split_name)\n",
        "  dataset = dataset.map(map_fn)\n",
        "\n",
        "  if is_validation:\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "  else:\n",
        "    dataset = dataset.shuffle(1024).batch(BATCH_SIZE)\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "kVGko-WT3bGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_dataset(map_image)"
      ],
      "metadata": {
        "id": "Wj0B2MXBJ9Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Model"
      ],
      "metadata": {
        "id": "1JMi-w68KCJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1YAZAeMGEJ1KgieYk1ju-S9DoshpMREeC\" width=\"60%\" height=\"60%\"/>"
      ],
      "metadata": {
        "id": "LcMrDTFzKEGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling Class"
      ],
      "metadata": {
        "id": "Ui8QfYbIKN8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(tf.keras.layers.Layer):\n",
        "  def call(self,inputs):\n",
        "    # Unpack the output of the encoder\n",
        "    my,sigma = inputs\n",
        "\n",
        "    # Get the size and dimensions of the batch\n",
        "    batch = tf.shape(mu)[0]\n",
        "    dim = tf.shape(mu)[1]\n",
        "\n",
        "    # Generate a random tensor\n",
        "    epsilon = tf.keras.backend.random_normal(shape = (batch,dim))\n",
        "\n",
        "    # Combine the inputs and noise\n",
        "    return mu + sigma * epsilon"
      ],
      "metadata": {
        "id": "VEx3e96CKJFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "uQyRnP83KxTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1eoxFK_UVSHd3a_5EHcCU8F8QDZlPiXfW\" width=\"60%\" height=\"60%\"/>"
      ],
      "metadata": {
        "id": "SC1XHtiQK6_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_layer(inputs,latent_dim):\n",
        "  # Add the Conv2D followed by BatchNormalization\n",
        "  x = tf.keras.layers.Conv2D(32,kernel_size = 3,strides = 2,padding = 'same',activation = 'relu',name = 'encode_conv1')(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2D(64,kernel_size = 3,strides = 2,padding = 'same',activation = 'relu',name = 'encode_conv2')(x)\n",
        "\n",
        "  # Assign to a different variable so can extract the shape later\n",
        "  batch_2 = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  # Flatten the features and feed into the Dense network\n",
        "  x = tf.keras.layers.Flatten(name = 'encode_flatten')(batch_2)\n",
        "\n",
        "  # we arbitrarily used 20 units here but feel free to change and see what results you get\n",
        "  x = tf.keras.layers.Dense(20,activation = 'relu',name = 'encode_dense')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  # Add output Dense network for mu and sigma, units equal to the declared latend_dim\n",
        "  mu = tf.keras.layers.Dense(latent_dim,name = 'latent_mu')(x)\n",
        "  sigma = tf.keras.layers.Dense(latent_dim,name = 'latent_sigma')(x)\n",
        "\n",
        "  return mu,sigma,batch_2.shape"
      ],
      "metadata": {
        "id": "eiTJ8EbuKyuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_model(latent_dim,input_shape):\n",
        "  # Declare the inputs tensor with the given shape\n",
        "  inputs = tf.keras.layers.Input(shape = input_shape)\n",
        "\n",
        "  # Get the output of the encoder_layers() function\n",
        "  mu,sigma,conv_shape = encoder_layers(inputs,latent_dim = LATENT_DIM)\n",
        "\n",
        "  # Feed mu and sigma to the sampling layer\n",
        "  z = Sampling()((mu,sigma))\n",
        "\n",
        "  # Build the whole encoder model\n",
        "  model = tf.keras.Model(inputs,outputs = [mu,sigma,z])\n",
        "\n",
        "  return model,conv_shape"
      ],
      "metadata": {
        "id": "NUugsQKuMkxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder"
      ],
      "metadata": {
        "id": "9XKJclsUNNah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_layer(inputs,conv_shape):\n",
        "  units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
        "  x = tf.keras.layers.Dense(units,activation = 'relu',name = 'decode_dense1')(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  # Reshape the output using the conv_shape dimensions\n",
        "  x = tf.keras.layers.Reshape((conv_shape[1],conv_shape[2],conv_shape[3]),name = 'decode_reshape')(x)\n",
        "\n",
        "  # Upsample the features back to the original dimensions\n",
        "  x = tf.keras.layers.Conv2DTranspose(64,kernel_size = 3,strides = 2,padding = 'same',activation = 'relu',name = 'decode_conv2d_2')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(32,kernel_size = 3,strides = 2,padding = 'same',activation = 'relu',name = 'decode_conv2d_3')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(1,kernel_size = 3,strides = 2,padding = 'same', activation = 'sigmoid',name = 'decode_final')(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "2zXa5X-iNO5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_model(latend_dim,conv_shape):\n",
        "  # Set the inputs to the shape of the latend space\n",
        "  inputs = tf.keras.layers.Input(shape = (latend_dim,))\n",
        "\n",
        "  # Get the output of the decoder layers\n",
        "  outputs = decoder_layers(inputs,conv_shape)\n",
        "\n",
        "  # Declare the inputs and outputs of the model\n",
        "  model = tf.keras.Model(inputs,outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "_8_eHy6BOvjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kullback-Leibler Divergence"
      ],
      "metadata": {
        "id": "mxKw3wfkPKLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kl_reconstruction_loss(mu,sigma):\n",
        "  kl_loss = 1 + sigma - tf.square(mu) = tf.math.exp(sigma)\n",
        "  kl_loss = tf.reduce_mean(kl_loss)\n",
        "\n",
        "  return kl_loss"
      ],
      "metadata": {
        "id": "zMqRpsvuPMzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE Model"
      ],
      "metadata": {
        "id": "SAVbFVnXPbtm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f5eGC0LNPfll"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}